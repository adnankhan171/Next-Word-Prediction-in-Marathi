{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80063163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/adnan/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd\n",
    "\n",
    "data = gutenberg.raw(\"shakespeare-hamlet.txt\")\n",
    "\n",
    "with open(\"hamlet.txt\",'w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e0512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 12:04:02.898212: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-06 12:04:02.942235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-06 12:04:04.128550: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4818\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adnan/SEM7_docs/venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759732445.728076   21558 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1759732445.735250   21558 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# yt1 \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    with open(\"hamlet.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read().lower()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'temp.txt' not found.\")\n",
    "    text = \"\"\n",
    "\n",
    "mytokenizer = Tokenizer()\n",
    "mytokenizer.fit_on_texts([text])\n",
    "total_words = len(mytokenizer.word_index) + 1\n",
    "print(total_words)\n",
    "\n",
    "input_sequences = []\n",
    "for line in text.split(\"\\n\"):\n",
    "  token_list = mytokenizer.texts_to_sequences([line])[0]\n",
    "  for i in range(1, len(token_list)):\n",
    "    n_gram_sequence = token_list[:i+1]\n",
    "    # print(n_gram_sequence)\n",
    "    input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding=\"pre\"))\n",
    "# print(my_input_sequences[0])\n",
    "# print(my_input_sequences[1])\n",
    "\n",
    "X = input_sequences[:,:-1]\n",
    "y = input_sequences[:,-1]\n",
    "# print(X[1])\n",
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# y[1]\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation=\"softmax\"))\n",
    "model.build(input_shape=(None, max_sequence_len-1))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# print(model.summary())\n",
    "history = model.fit(X_train,y_train,epochs=100,verbose=1, validation_data=(X_test,y_test))\n",
    "\n",
    "# model evaluation\n",
    "print(\"\\n--- Final Model Evaluation ---\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Test Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc453d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
